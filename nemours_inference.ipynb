{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07247397",
   "metadata": {},
   "source": [
    "# Nemours HDF5 Dataset Inference\n",
    "\n",
    "This notebook performs comprehensive inference on the Nemours HDF5 dataset:\n",
    "\n",
    "**Tasks:**\n",
    "1. Run inference on full dataset (all B-scans) and save results\n",
    "2. Randomly sample 200 images with at least 1 detection and visualize\n",
    "3. Identify volumes containing both Fovea and SCR classes\n",
    "4. Generate volume-specific inference results\n",
    "\n",
    "**Dataset**: `/home/suraj/Data/Nemours/Nemours_Jing_0929.h5`  \n",
    "\n",
    "**Model**: `checkpoints12022205/best_model.pth`  **Output**: `nemours_inference/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79ffcf",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585523f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Threshold: 0.5\n",
      "Device: cuda\n",
      "Output Directory: nemours_inference\n",
      "HDF5 Dataset: /home/suraj/Data/Nemours/Nemours_Jing_0929.h5\n",
      "Model Checkpoint: /home/suraj/Git/RCNN-OCT/checkpoints12022205/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.ops as ops\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import project modules\n",
    "import sys\n",
    "sys.path.insert(0, '/home/suraj/Git/RCNN-OCT')\n",
    "from inference import load_model\n",
    "\n",
    "# Configuration\n",
    "HDF5_PATH = Path(\"/home/suraj/Data/Nemours/Nemours_Jing_0929.h5\")\n",
    "CHECKPOINT_PATH = Path(\"/home/suraj/Git/RCNN-OCT/checkpoints12022205/best_model.pth\")\n",
    "OUTPUT_DIR = Path(\"nemours_inference\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SCORE_THRESHOLD = 0.5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Score Threshold: {SCORE_THRESHOLD}\")\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "print(f\"HDF5 Dataset: {HDF5_PATH}\")\n",
    "print(f\"Model Checkpoint: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446397e9",
   "metadata": {},
   "source": [
    "## 2. Load HDF5 Dataset and Parse Volumes\n",
    "\n",
    "The HDF5 file contains:\n",
    "- `images`: (N, 496, 768) uint8 array of OCT B-scans\n",
    "- `names`: (N,) array of volume identifiers (e.g., \"256_L_1_1.e2e\")\n",
    "- `bscan_indices`: (N,) array of B-scan indices within each volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dc5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HDF5 dataset...\n",
      "\n",
      "============================================================\n",
      "Dataset loaded: (2540, 496, 768)\n",
      "Total volumes: 104\n",
      "Total B-scans: 2540\n",
      "Image dimensions: 496 x 768\n",
      "============================================================\n",
      "\n",
      "Top 10 volumes by B-scan count:\n",
      " 1. 142_R_3                   - 31 B-scans\n",
      " 2. 62_R_6                    - 31 B-scans\n",
      " 3. 242_L_1                   - 31 B-scans\n",
      " 4. 25_R_3                    - 31 B-scans\n",
      " 5. 247_L_1_1                 - 31 B-scans\n",
      " 6. 62_L_6                    - 31 B-scans\n",
      " 7. 244_R_1                   - 31 B-scans\n",
      " 8. 237_R_1                   - 31 B-scans\n",
      " 9. 257_R_1_1                 - 31 B-scans\n",
      "10. 72_R_10                   - 31 B-scans\n"
     ]
    }
   ],
   "source": [
    "def load_hdf5_volumes(hdf5_path):\n",
    "    \"\"\"Load HDF5 file and organize B-scans by volume.\"\"\"\n",
    "    with h5py.File(hdf5_path, 'r') as f:\n",
    "        images = f['images'][:]\n",
    "        names = f['names'][:]\n",
    "        bscan_indices = f['bscan_indices'][:]\n",
    "    \n",
    "    # Decode volume names\n",
    "    names_decoded = [n.decode() if isinstance(n, bytes) else str(n) for n in names]\n",
    "    \n",
    "    # Group B-scans by volume\n",
    "    volumes = defaultdict(list)\n",
    "    for idx, (name, bscan_idx) in enumerate(zip(names_decoded, bscan_indices)):\n",
    "        # Remove .e2e extension and use as volume ID\n",
    "        volume_id = name.replace('.e2e', '')\n",
    "        volumes[volume_id].append({\n",
    "            'global_idx': idx,\n",
    "            'bscan_idx': int(bscan_idx),\n",
    "            'image': images[idx]\n",
    "        })\n",
    "    \n",
    "    # Sort B-scans within each volume by bscan_idx\n",
    "    for volume_id in volumes:\n",
    "        volumes[volume_id].sort(key=lambda x: x['bscan_idx'])\n",
    "    \n",
    "    return volumes, images.shape\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading HDF5 dataset...\")\n",
    "volumes, data_shape = load_hdf5_volumes(HDF5_PATH)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Dataset loaded: {data_shape}\")\n",
    "print(f\"Total volumes: {len(volumes)}\")\n",
    "print(f\"Total B-scans: {data_shape[0]}\")\n",
    "print(f\"Image dimensions: {data_shape[1]} x {data_shape[2]}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Display volume statistics\n",
    "volume_counts = {vol: len(bscans) for vol, bscans in volumes.items()}\n",
    "sorted_volumes = sorted(volume_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nTop 10 volumes by B-scan count:\")\n",
    "for i, (vol, count) in enumerate(sorted_volumes[:10], 1):\n",
    "    print(f\"{i:2d}. {vol:25s} - {count:2d} B-scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a723c8f",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a61924f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "✓ Model loaded successfully!\n",
      "NMS threshold set to: 0.3\n",
      "✓ Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "model = load_model(CHECKPOINT_PATH, device=DEVICE)\n",
    "model.eval()\n",
    "print(\"✓ Model loaded successfully!\")\n",
    "model.roi_heads.nms_thresh = 0.3  # default is 0.5\n",
    "print(f\"NMS threshold set to: {model.roi_heads.nms_thresh}\")\n",
    "\n",
    "print(\"✓ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c4d13",
   "metadata": {},
   "source": [
    "## 4. Task 1: Run Inference on Full Dataset\n",
    "\n",
    "Run inference on all B-scans in the dataset and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87cdadde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on full dataset (2540 B-scans)...\n",
      "Score threshold: 0.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing volumes: 100%|██████████| 104/104 [05:58<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Inference complete for 2540 B-scans across 104 volumes\n",
      "✓ Results saved to: nemours_inference/full_dataset_inference.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def run_inference_on_image(model, image_np, device, score_threshold=0.5):\n",
    "    \"\"\"Run inference on a single OCT B-scan image.\"\"\"\n",
    "    # Normalize image\n",
    "    image_np = np.asarray(image_np, dtype=np.float32)\n",
    "    if image_np.max() > 1.0:\n",
    "        image_np = image_np / 255.0\n",
    "    \n",
    "    # Convert to tensor\n",
    "    image_tensor = torch.from_numpy(image_np)\n",
    "    if image_tensor.ndim == 2:\n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Convert grayscale to RGB (3 channels)\n",
    "    if image_tensor.shape[0] == 1:\n",
    "        image_tensor = image_tensor.repeat(3, 1, 1)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model([image_tensor.to(device)])\n",
    "    \n",
    "    output = outputs[0]\n",
    "    pred_boxes = output[\"boxes\"].cpu().numpy()\n",
    "    pred_scores = output[\"scores\"].cpu().numpy()\n",
    "    pred_labels = output[\"labels\"].cpu().numpy()\n",
    "    \n",
    "    # Filter by score threshold\n",
    "    keep = pred_scores >= score_threshold\n",
    "    pred_boxes = pred_boxes[keep]\n",
    "    pred_scores = pred_scores[keep]\n",
    "    pred_labels = pred_labels[keep]\n",
    "    \n",
    "    return {\n",
    "        'image': image_tensor.cpu(),\n",
    "        'pred_boxes': pred_boxes,\n",
    "        'pred_scores': pred_scores,\n",
    "        'pred_labels': pred_labels\n",
    "    }\n",
    "\n",
    "# Run inference on ALL B-scans in the entire dataset\n",
    "all_results = {}  # {volume_id: [results_for_bscans]}\n",
    "\n",
    "print(f\"Running inference on full dataset ({data_shape[0]} B-scans)...\")\n",
    "print(f\"Score threshold: {SCORE_THRESHOLD}\\n\")\n",
    "\n",
    "for volume_id, bscans in tqdm(volumes.items(), desc=\"Processing volumes\"):\n",
    "    volume_results = []\n",
    "    for bscan_info in bscans:\n",
    "        result = run_inference_on_image(\n",
    "            model, \n",
    "            bscan_info['image'], \n",
    "            DEVICE, \n",
    "            score_threshold=SCORE_THRESHOLD\n",
    "        )\n",
    "        result['bscan_idx'] = bscan_info['bscan_idx']\n",
    "        result['global_idx'] = bscan_info['global_idx']\n",
    "        result['volume_id'] = volume_id\n",
    "        volume_results.append(result)\n",
    "    \n",
    "    all_results[volume_id] = volume_results\n",
    "\n",
    "# Save all results to pickle file\n",
    "inference_pkl = OUTPUT_DIR / \"full_dataset_inference.pkl\"\n",
    "with open(inference_pkl, 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "total_bscans = sum(len(v) for v in all_results.values())\n",
    "print(f\"\\n✓ Inference complete for {total_bscans} B-scans across {len(all_results)} volumes\")\n",
    "print(f\"✓ Results saved to: {inference_pkl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23e37e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded inference results from: /home/suraj/Git/RCNN-OCT/nemours_inference/full_dataset_inference.pkl\n",
      "✓ Loaded 104 volumes\n",
      "✓ Total B-scans: 2540\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load pre-computed inference results instead of running inference again\n",
    "inference_pkl_path = '/home/suraj/Git/RCNN-OCT/nemours_inference/full_dataset_inference.pkl'\n",
    "\n",
    "with open(inference_pkl_path, 'rb') as f:\n",
    "    all_results = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded inference results from: {inference_pkl_path}\")\n",
    "print(f\"✓ Loaded {len(all_results)} volumes\")\n",
    "total_bscans = sum(len(v) for v in all_results.values())\n",
    "print(f\"✓ Total B-scans: {total_bscans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e906142",
   "metadata": {},
   "source": [
    "## 5. Task 2: Sample 200 Images with Detections\n",
    "\n",
    "Randomly select 200 B-scans that have at least 1 detection and save visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "350df665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target volumes: 20\n",
      "Volumes: 48_R_8, 242_R_1, 124_R_5, 239_R_1, 152_R_3_1, 124_L_5, 259_R_1, 30_L_5, 240_R_1, 240_L_1, 62_L_6, 22_R_5, 185_R_3, 241_R_2_1, 30_R_5, 47_R_6, 47_L_6, 86_L_6, 247_R_1, 62_R_6\n",
      "\n",
      "============================================================\n",
      "Volumes found: 20/20\n",
      "Total B-scans collected: 620\n",
      "============================================================\n",
      "\n",
      "B-scans per volume:\n",
      "  48_R_8               - 31 B-scans\n",
      "  242_R_1              - 31 B-scans\n",
      "  124_R_5              - 31 B-scans\n",
      "  239_R_1              - 31 B-scans\n",
      "  152_R_3_1            - 31 B-scans\n",
      "  124_L_5              - 31 B-scans\n",
      "  259_R_1              - 31 B-scans\n",
      "  30_L_5               - 31 B-scans\n",
      "  240_R_1              - 31 B-scans\n",
      "  240_L_1              - 31 B-scans\n",
      "  62_L_6               - 31 B-scans\n",
      "  22_R_5               - 31 B-scans\n",
      "  185_R_3              - 31 B-scans\n",
      "  241_R_2_1            - 31 B-scans\n",
      "  30_R_5               - 31 B-scans\n",
      "  47_R_6               - 31 B-scans\n",
      "  47_L_6               - 31 B-scans\n",
      "  86_L_6               - 31 B-scans\n",
      "  247_R_1              - 31 B-scans\n",
      "  62_R_6               - 31 B-scans\n",
      "\n",
      "Generating visualizations for 620 B-scans...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating visualizations: 100%|██████████| 620/620 [03:19<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Visualizations saved to: nemours_inference/selected_20_volumes_detections\n",
      "\n",
      "Extracting raw images from HDF5 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting raw images: 100%|██████████| 620/620 [00:15<00:00, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Raw images saved to: nemours_inference/selected_20_volumes_raw_images\n",
      "✓ Metadata saved to: nemours_inference/selected_20_volumes_raw_images/selected_volumes_metadata.json\n",
      "\n",
      "Raw images are 496x768 pixels from the original HDF5 dataset.\n",
      "Each image is saved as a grayscale PNG with no annotations or borders.\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "  Target volumes: 20\n",
      "  Volumes found: 20\n",
      "  Total B-scans extracted: 620\n",
      "  Output directory: nemours_inference/selected_20_volumes_raw_images\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define specific volumes to sample from\n",
    "target_volumes = [\n",
    "    '48_R_8', '242_R_1', '124_R_5', '239_R_1', '152_R_3_1',\n",
    "    '124_L_5', '259_R_1', '30_L_5', '240_R_1', '240_L_1',\n",
    "    '62_L_6', '22_R_5', '185_R_3', '241_R_2_1', '30_R_5',\n",
    "    '47_R_6', '47_L_6', '86_L_6', '247_R_1', '62_R_6'\n",
    "]\n",
    "\n",
    "print(f\"Target volumes: {len(target_volumes)}\")\n",
    "print(\"Volumes:\", ', '.join(target_volumes))\n",
    "\n",
    "# Collect all B-scans from the specified volumes\n",
    "sampled_results = []\n",
    "volumes_found = []\n",
    "volumes_not_found = []\n",
    "\n",
    "for volume_id in target_volumes:\n",
    "    if volume_id in all_results:\n",
    "        volumes_found.append(volume_id)\n",
    "        # Add all B-scans from this volume\n",
    "        for result in all_results[volume_id]:\n",
    "            sampled_results.append(result)\n",
    "    else:\n",
    "        volumes_not_found.append(volume_id)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Volumes found: {len(volumes_found)}/{len(target_volumes)}\")\n",
    "print(f\"Total B-scans collected: {len(sampled_results)}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if volumes_not_found:\n",
    "    print(f\"\\n⚠ Warning: {len(volumes_not_found)} volumes not found in dataset:\")\n",
    "    for vol in volumes_not_found:\n",
    "        print(f\"  - {vol}\")\n",
    "\n",
    "# Display breakdown by volume\n",
    "print(f\"\\nB-scans per volume:\")\n",
    "for volume_id in volumes_found:\n",
    "    num_bscans = len(all_results[volume_id])\n",
    "    print(f\"  {volume_id:20s} - {num_bscans:2d} B-scans\")\n",
    "\n",
    "# Create visualization function\n",
    "def visualize_detection(result, save_path, min_confidence=0.7):\n",
    "    \"\"\"Visualize predictions for a single B-scan.\"\"\"\n",
    "    label_names = {1: \"Fovea\", 2: \"SCR\"}\n",
    "    label_colors = {1: \"green\", 2: \"red\"}\n",
    "    \n",
    "    # Get image\n",
    "    image = result['image']\n",
    "    if image.dim() == 3 and image.shape[0] == 3:\n",
    "        image_np = image[0].numpy()\n",
    "    else:\n",
    "        image_np = image.squeeze().numpy()\n",
    "        \n",
    "     # Filter predictions by confidence threshold\n",
    "    high_conf_mask = result['pred_scores'] >= min_confidence\n",
    "    filtered_boxes = result['pred_boxes'][high_conf_mask]\n",
    "    filtered_scores = result['pred_scores'][high_conf_mask]\n",
    "    filtered_labels = result['pred_labels'][high_conf_mask]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "    \n",
    "    # Plot image\n",
    "    ax.imshow(image_np, cmap=\"gray\")\n",
    "    title = f\"{result['volume_id']} - B-scan {result['bscan_idx']:03d}\"\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # Plot only high-confidence predictions\n",
    "    for box, score, label in zip(filtered_boxes, filtered_scores, filtered_labels):\n",
    "        label_int = int(label)\n",
    "        color = label_colors.get(label_int, \"yellow\")\n",
    "        label_text = label_names.get(label_int, f\"Class {label_int}\")\n",
    "        \n",
    "        x1, y1, x2, y2 = box\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), x2 - x1, y2 - y1,\n",
    "            linewidth=2.5, edgecolor=color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        bbox_props = dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7, edgecolor=\"none\")\n",
    "        ax.text(\n",
    "            x1, y1 - 8, f\"{label_text}: {score:.2f}\", \n",
    "            color=\"white\", fontsize=10, weight=\"bold\", \n",
    "            bbox=bbox_props, verticalalignment=\"top\"\n",
    "        )\n",
    "    \n",
    "    # Add detection count (only high-confidence detections)\n",
    "    num_detections = len(filtered_boxes)\n",
    "    num_fovea = sum(1 for l in filtered_labels if l == 1)\n",
    "    num_scr = sum(1 for l in filtered_labels if l == 2)\n",
    "    \n",
    "    info_text = f\"Detections (conf≥{min_confidence}): {num_detections} (Fovea: {num_fovea}, SCR: {num_scr})\"\n",
    "    ax.text(\n",
    "        0.02, 0.98, info_text,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=11, weight=\"bold\",\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\", alpha=0.9)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Save visualizations for sampled B-scans (with detections)\n",
    "sample_dir = OUTPUT_DIR / f\"selected_{len(target_volumes)}_volumes_detections\"\n",
    "sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nGenerating visualizations for {len(sampled_results)} B-scans...\")\n",
    "for i, result in enumerate(tqdm(sampled_results, desc=\"Creating visualizations\")):\n",
    "    filename = f\"{result['volume_id']}_bscan_{result['bscan_idx']:03d}.png\"\n",
    "    save_path = sample_dir / filename\n",
    "    visualize_detection(result, save_path)\n",
    "\n",
    "print(f\"\\n✓ Visualizations saved to: {sample_dir}\")\n",
    "\n",
    "# Now save raw images from the original HDF5 dataset\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Create directory for raw images\n",
    "raw_sample_dir = OUTPUT_DIR / f\"selected_{len(target_volumes)}_volumes_raw_images\"\n",
    "raw_sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare metadata list for JSON\n",
    "sampled_metadata = []\n",
    "\n",
    "print(f\"\\nExtracting raw images from HDF5 dataset...\")\n",
    "with h5py.File(HDF5_PATH, 'r') as f:\n",
    "    images = f['images'][:]\n",
    "    names = f['names'][:]\n",
    "    bscan_indices = f['bscan_indices'][:]\n",
    "    \n",
    "    for i, result in enumerate(tqdm(sampled_results, desc=\"Extracting raw images\")):\n",
    "        volume_id = result['volume_id']\n",
    "        bscan_idx = result['bscan_idx']\n",
    "        global_idx = result['global_idx']\n",
    "        \n",
    "        # Get the raw image from HDF5\n",
    "        raw_image = images[global_idx]\n",
    "        \n",
    "        # Create filename\n",
    "        filename = f\"{volume_id}_bscan_{bscan_idx:03d}.png\"\n",
    "        save_path = raw_sample_dir / filename\n",
    "        \n",
    "        # Save as PNG using PIL (preserves original dimensions and pixel values)\n",
    "        img_pil = Image.fromarray(raw_image)\n",
    "        img_pil.save(save_path)\n",
    "        \n",
    "        # Store metadata\n",
    "        metadata_entry = {\n",
    "            \"index\": i,\n",
    "            \"filename\": filename,\n",
    "            \"volume_id\": volume_id,\n",
    "            \"bscan_index\": int(bscan_idx),\n",
    "            \"global_index\": int(global_idx),\n",
    "            \"image_shape\": list(raw_image.shape),\n",
    "            \"num_detections\": len(result['pred_boxes']),\n",
    "            \"detection_labels\": [int(label) for label in result['pred_labels']],\n",
    "            \"detection_scores\": [float(score) for score in result['pred_scores']]\n",
    "        }\n",
    "        sampled_metadata.append(metadata_entry)\n",
    "\n",
    "# Save metadata to JSON\n",
    "metadata_path = raw_sample_dir / \"selected_volumes_metadata.json\"\n",
    "with open(metadata_path, 'w') as json_file:\n",
    "    json.dump({\n",
    "        \"total_samples\": len(sampled_results),\n",
    "        \"num_target_volumes\": len(target_volumes),\n",
    "        \"volumes_found\": volumes_found,\n",
    "        \"volumes_not_found\": volumes_not_found,\n",
    "        \"target_volumes\": target_volumes,\n",
    "        \"source_hdf5\": str(HDF5_PATH),\n",
    "        \"image_dimensions\": f\"{data_shape[1]}x{data_shape[2]}\",\n",
    "        \"samples\": sampled_metadata\n",
    "    }, json_file, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Raw images saved to: {raw_sample_dir}\")\n",
    "print(f\"✓ Metadata saved to: {metadata_path}\")\n",
    "print(f\"\\nRaw images are {data_shape[1]}x{data_shape[2]} pixels from the original HDF5 dataset.\")\n",
    "print(f\"Each image is saved as a grayscale PNG with no annotations or borders.\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SUMMARY:\")\n",
    "print(f\"  Target volumes: {len(target_volumes)}\")\n",
    "print(f\"  Volumes found: {len(volumes_found)}\")\n",
    "print(f\"  Total B-scans extracted: {len(sampled_results)}\")\n",
    "print(f\"  Output directory: {raw_sample_dir}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27569f18",
   "metadata": {},
   "source": [
    "## 6. Identify Volumes with Both Fovea and SCR Classes\n",
    "\n",
    "Find volumes that contain both Fovea (label 1) and SCR (label 2) detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Volumes containing BOTH Fovea and SCR:\n",
      "============================================================\n",
      "Total volumes with both classes: 52\n",
      "\n",
      "Volume list:\n",
      "  1. 114_R_5                        (31 B-scans)\n",
      "  2. 121_L_2                        (31 B-scans)\n",
      "  3. 121_L_4                        (5 B-scans)\n",
      "  4. 121_R_4                        (5 B-scans)\n",
      "  5. 124_L_5                        (31 B-scans)\n",
      "  6. 124_R_5                        (31 B-scans)\n",
      "  7. 142_L_3                        (31 B-scans)\n",
      "  8. 152_L_3_1                      (31 B-scans)\n",
      "  9. 185_L_3                        (31 B-scans)\n",
      " 10. 185_R_3                        (31 B-scans)\n",
      " 11. 22_L_5                         (31 B-scans)\n",
      " 12. 22_R_5                         (31 B-scans)\n",
      " 13. 240_L_1                        (31 B-scans)\n",
      " 14. 240_R_1                        (31 B-scans)\n",
      " 15. 241_L_1                        (31 B-scans)\n",
      " 16. 241_L_2_1                      (31 B-scans)\n",
      " 17. 241_L_2_2                      (5 B-scans)\n",
      " 18. 241_R_1                        (31 B-scans)\n",
      " 19. 241_R_2_1                      (31 B-scans)\n",
      " 20. 241_R_2_2                      (5 B-scans)\n",
      " 21. 243_L_1                        (31 B-scans)\n",
      " 22. 244_R_1                        (31 B-scans)\n",
      " 23. 245_R_1_1                      (31 B-scans)\n",
      " 24. 245_R_1_2                      (5 B-scans)\n",
      " 25. 246_R_1                        (31 B-scans)\n",
      " 26. 247_L_1_1                      (31 B-scans)\n",
      " 27. 247_L_1_2                      (5 B-scans)\n",
      " 28. 247_R_1                        (31 B-scans)\n",
      " 29. 248_R_1_1                      (31 B-scans)\n",
      " 30. 250_R_1                        (31 B-scans)\n",
      " 31. 256_L_1_1                      (28 B-scans)\n",
      " 32. 256_L_1_4                      (5 B-scans)\n",
      " 33. 256_R_1_1                      (31 B-scans)\n",
      " 34. 259_L_1                        (31 B-scans)\n",
      " 35. 259_R_1                        (31 B-scans)\n",
      " 36. 25_L_3                         (31 B-scans)\n",
      " 37. 25_R_3                         (31 B-scans)\n",
      " 38. 30_L_5                         (31 B-scans)\n",
      " 39. 30_R_5                         (31 B-scans)\n",
      " 40. 34_R_5                         (31 B-scans)\n",
      " 41. 47_L_6                         (31 B-scans)\n",
      " 42. 47_R_6                         (31 B-scans)\n",
      " 43. 48_L_8                         (31 B-scans)\n",
      " 44. 62_L_6                         (31 B-scans)\n",
      " 45. 62_R_6                         (31 B-scans)\n",
      " 46. 80_L_7_2                       (5 B-scans)\n",
      " 47. 80_R_7_1                       (31 B-scans)\n",
      " 48. 80_R_7_2                       (5 B-scans)\n",
      " 49. 86_L_6                         (31 B-scans)\n",
      " 50. 86_R_6                         (31 B-scans)\n",
      " 51. 90_L_3                         (31 B-scans)\n",
      " 52. 97_R_6                         (31 B-scans)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Analyze each volume for class labels\n",
    "volumes_with_both = []\n",
    "\n",
    "for volume_id, volume_results in all_results.items():\n",
    "    has_fovea = False\n",
    "    has_scr = False\n",
    "    \n",
    "    for result in volume_results:\n",
    "        labels = result['pred_labels']\n",
    "        if 1 in labels:\n",
    "            has_fovea = True\n",
    "        if 2 in labels:\n",
    "            has_scr = True\n",
    "        \n",
    "        if has_fovea and has_scr:\n",
    "            break\n",
    "    \n",
    "    if has_fovea and has_scr:\n",
    "        volumes_with_both.append(volume_id)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Volumes containing BOTH Fovea and SCR:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total volumes with both classes: {len(volumes_with_both)}\\n\")\n",
    "\n",
    "if len(volumes_with_both) > 0:\n",
    "    print(\"Volume list:\")\n",
    "    for i, vol in enumerate(sorted(volumes_with_both), 1):\n",
    "        num_bscans = len(all_results[vol])\n",
    "        print(f\"{i:3d}. {vol:30s} ({num_bscans} B-scans)\")\n",
    "else:\n",
    "    print(\"No volumes found with both Fovea and SCR detections.\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb17430",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completes the following tasks:\n",
    "\n",
    "### ✅ Task 1: Full Dataset Inference\n",
    "- Ran inference on all {data_shape[0]} B-scans across {len(volumes)} volumes\n",
    "- Results saved to: `nemours_inference/full_dataset_inference.pkl`\n",
    "\n",
    "### ✅ Task 2: Sample 200 Images with Detections\n",
    "- Randomly sampled 200 B-scans with at least 1 detection\n",
    "- Visualizations (with bounding boxes) saved to: `nemours_inference/sampled_200_detections/`\n",
    "- Raw images (original HDF5, no annotations) saved to: `nemours_inference/sampled_200_raw_images/`\n",
    "- Metadata JSON file saved to: `nemours_inference/sampled_200_raw_images/sampled_images_metadata.json`\n",
    "\n",
    "### ✅ Task 3: Identify Volumes with Both Classes\n",
    "- Found {len(volumes_with_both)} volumes containing both Fovea and SCR detections\n",
    "- List available in Section 6\n",
    "\n",
    "### ✅ Task 4: Volume-Specific Inference Function\n",
    "- Function `generate_volume_inference()` available for generating complete volume results\n",
    "- Saves all B-scans (with or without detections) to: `nemours_inference/{volume_id}/`\n",
    "- See Section 8 for usage examples\n",
    "\n",
    "**All outputs are saved in the `nemours_inference/` directory.**\n",
    "\n",
    "### Raw Images Details\n",
    "The raw images are saved as grayscale PNG files with:\n",
    "- Original dimensions: 496×768 pixels (from HDF5 dataset)\n",
    "- No matplotlib borders, titles, or annotations\n",
    "- Pixel values preserved from the original dataset\n",
    "- Each image filename format: `{volume_id}_bscan_{bscan_index:03d}.png`\n",
    "- Complete metadata including detection info in JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d99f4",
   "metadata": {},
   "source": [
    "## How to Use the Raw Images and Metadata\n",
    "\n",
    "The JSON metadata file contains complete information about each sampled image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a83370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and inspect the metadata\n",
    "import json\n",
    "\n",
    "metadata_path = OUTPUT_DIR / \"sampled_200_raw_images\" / \"sampled_images_metadata.json\"\n",
    "\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Total samples: {metadata['total_samples']}\")\n",
    "print(f\"Random seed: {metadata['random_seed']}\")\n",
    "print(f\"Source HDF5: {metadata['source_hdf5']}\")\n",
    "print(f\"Image dimensions: {metadata['image_dimensions']}\")\n",
    "print(f\"\\nFirst 3 samples:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for sample in metadata['samples'][:3]:\n",
    "    print(f\"\\nFilename: {sample['filename']}\")\n",
    "    print(f\"  Volume ID: {sample['volume_id']}\")\n",
    "    print(f\"  B-scan Index: {sample['bscan_index']}\")\n",
    "    print(f\"  Global Index: {sample['global_index']}\")\n",
    "    print(f\"  Image Shape: {sample['image_shape']}\")\n",
    "    print(f\"  Detections: {sample['num_detections']} (Labels: {sample['detection_labels']})\")\n",
    "    print(f\"  Confidence Scores: {[f'{s:.3f}' for s in sample['detection_scores']]}\")\n",
    "    \n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"\\nYou can use this metadata to:\")\n",
    "print(\"1. Create bounding box annotations for these images\")\n",
    "print(\"2. Track which volume and B-scan each image came from\")\n",
    "print(\"3. Filter images by detection type (Fovea=1, SCR=2)\")\n",
    "print(\"4. Re-extract specific images from the original HDF5 using global_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
